{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "9iIDd8lDUH44"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import csv\n",
        "import re\n",
        "from collections import defaultdict"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class NaiveBayes:\n",
        "    def __init__(self):\n",
        "        self.class_priors = {}\n",
        "        self.word_likelihoods = defaultdict(lambda: defaultdict(float))\n",
        "        self.vocabulary_size = 0\n",
        "        self.total_words_per_class = defaultdict(int)\n",
        "        self.stop_words = set([\n",
        "            'the','is','i','as','product'\n",
        "        ])\n",
        "\n",
        "    def preprocess_text(self, text):\n",
        "        # Convert to lowercase\n",
        "        text = text.lower()\n",
        "        # Remove punctuation and special characters\n",
        "        text = re.sub(r'[^a-z0-9\\s]', '', text)\n",
        "        # Remove stop words\n",
        "        text = ' '.join(word for word in text.split() if word not in self.stop_words)\n",
        "        return text.strip()\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        # Calculate prior probabilities\n",
        "        total_reviews = len(y)\n",
        "        class_counts = defaultdict(int)\n",
        "\n",
        "        # Count occurrences of each class\n",
        "        for label in y:\n",
        "            class_counts[label] += 1\n",
        "\n",
        "        self.class_priors = {cls: count / total_reviews for cls, count in class_counts.items()}\n",
        "\n",
        "        # Count word frequencies for each class\n",
        "        word_counts = defaultdict(lambda: defaultdict(int))\n",
        "\n",
        "        for review, label in zip(X, y):\n",
        "            for word in review.split():\n",
        "                word_counts[label][word] += 1\n",
        "                self.total_words_per_class[label] += 1\n",
        "\n",
        "        # Calculate the vocabulary size\n",
        "        all_words = set(word for counts in word_counts.values() for word in counts.keys())\n",
        "        self.vocabulary_size = len(all_words)\n",
        "\n",
        "        # Calculate log-likelihoods with Laplace smoothing\n",
        "        for cls, counts in word_counts.items():\n",
        "            for word in all_words:\n",
        "                word_count = counts.get(word, 0)\n",
        "                # Apply Laplace smoothing\n",
        "                self.word_likelihoods[cls][word] = (word_count + 1) / (self.total_words_per_class[cls] + self.vocabulary_size)\n",
        "\n",
        "    def predict(self, review):\n",
        "        log_probs = {}\n",
        "        for cls in self.class_priors.keys():\n",
        "            log_probs[cls] = np.log(self.class_priors[cls])\n",
        "            for word in review.split():\n",
        "                if word in self.word_likelihoods[cls]:\n",
        "                    log_probs[cls] += np.log(self.word_likelihoods[cls][word])\n",
        "                else:\n",
        "                    # Use Laplace smoothing for unseen words\n",
        "                    log_probs[cls] += np.log(1 / (self.total_words_per_class[cls] + self.vocabulary_size))\n",
        "        return max(log_probs, key=log_probs.get)\n"
      ],
      "metadata": {
        "id": "9LSFKnT-UMwC"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to read data from CSV\n",
        "def read_csv(file_path):\n",
        "    reviews = []\n",
        "    ratings = []\n",
        "\n",
        "    with open(file_path, mode='r', encoding='utf-8') as csvfile:\n",
        "        csvreader = csv.DictReader(csvfile)\n",
        "        for row in csvreader:\n",
        "            reviews.append(row['review'])\n",
        "            ratings.append(int(row['rating']))\n",
        "\n",
        "    return reviews, ratings\n",
        "\n",
        "# Read data from the CSV file\n",
        "X, y = read_csv('zomato_reviews.csv')"
      ],
      "metadata": {
        "id": "0hqeETS4UTBM"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the Naive Bayes classifier\n",
        "nb_classifier = NaiveBayes()"
      ],
      "metadata": {
        "id": "PLSoaMloUW1L"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Clean the reviews\n",
        "X_cleaned = [nb_classifier.preprocess_text(review) for review in X]"
      ],
      "metadata": {
        "id": "PqCtv9nMUZo_"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert ratings to classes\n",
        "def classify_rating(rating):\n",
        "    if rating in [1, 2]:\n",
        "        return 'Bad'\n",
        "    elif rating == 3:\n",
        "        return 'Okay'\n",
        "    else:  # rating in [4, 5]\n",
        "        return 'Good'"
      ],
      "metadata": {
        "id": "faoYWHE5UZeh"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert ratings to classes\n",
        "y_classes = [classify_rating(rating) for rating in y]"
      ],
      "metadata": {
        "id": "SPOPBoUNUZS0"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Manually split the dataset into training (70%), validation (10%), and test (20%)\n",
        "def split_dataset(X, y, train_size=0.7, val_size=0.1):\n",
        "    total_reviews = len(y)\n",
        "    train_end = int(train_size * total_reviews)\n",
        "    val_end = train_end + int(val_size * total_reviews)\n",
        "\n",
        "    X_train = X[:train_end]\n",
        "    y_train = y[:train_end]\n",
        "    X_val = X[train_end:val_end]\n",
        "    y_val = y[train_end:val_end]\n",
        "    X_test = X[val_end:]\n",
        "    y_test = y[val_end:]\n",
        "\n",
        "    return X_train, y_train, X_val, y_val, X_test, y_test\n",
        "\n",
        "# Split the dataset\n",
        "X_train, y_train, X_val, y_val, X_test, y_test = split_dataset(X_cleaned, y_classes)"
      ],
      "metadata": {
        "id": "9OiAKOKXUh6c"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the classifier\n",
        "nb_classifier.fit(X_train, y_train)\n",
        "#print(y_train)"
      ],
      "metadata": {
        "id": "qgi35KFhUh27"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Validate the classifier on the validation set\n",
        "val_predictions = [nb_classifier.predict(review) for review in X_val]\n",
        "val_accuracy = np.mean(np.array(val_predictions) == y_val)\n",
        "\n",
        "print(f'Validation Accuracy: {val_accuracy:.2f}')\n",
        "\n",
        "# Test the classifier on the test set\n",
        "test_predictions = [nb_classifier.predict(review) for review in X_test]\n",
        "test_accuracy = np.mean(np.array(test_predictions) == y_test)\n",
        "\n",
        "print(f'Test Accuracy: {test_accuracy:.2f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cRdw86CRUhxZ",
        "outputId": "9a984efa-3400-4921-cffd-6dea1fbba617"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 0.51\n",
            "Test Accuracy: 0.47\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example of predicting a single review\n",
        "while(1):\n",
        "  print(\"Enter stop to stop giving review : \")\n",
        "  example_review = input(\"Enter a review: \")\n",
        "  if(example_review==\"stop\"):\n",
        "    break\n",
        "  example_review_cleaned = nb_classifier.preprocess_text(example_review)\n",
        "  predicted_class = nb_classifier.predict(example_review_cleaned)\n",
        "  print(f'Predicted class for the review \"{example_review}\": {predicted_class}')\n",
        "  print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GyUN0Nt3UmD1",
        "outputId": "3150ac87-e3a5-4b3f-e17f-f693a1fef43f"
      },
      "execution_count": 47,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter stop to stop giving review : \n",
            "Enter a review: i loved the product\n",
            "Predicted class for the review \"i loved the product\": Good\n",
            "\n",
            "Enter stop to stop giving review : \n",
            "Enter a review: i didn't liked the product\n",
            "Predicted class for the review \"i didn't liked the product\": Bad\n",
            "\n",
            "Enter stop to stop giving review : \n",
            "Enter a review: stop\n"
          ]
        }
      ]
    }
  ]
}